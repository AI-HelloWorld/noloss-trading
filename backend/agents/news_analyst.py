"""
æ–°é—»åˆ†æå¸ˆæ™ºèƒ½ä½“
"""
import datetime
import json
import re
from typing import Dict, Optional, List
from loguru import logger
import aiohttp

from backend.agents.base_agent import BaseAgent, AgentRole, AgentAnalysis
from backend.agents.prompts import NEWS_ANALYST_PROMPT, get_risk_control_context
from backend.config import settings


class NewsAnalyst(BaseAgent):
    """æ–°é—»åˆ†æå¸ˆ - ç›‘æ§å…¨çƒæ–°é—»ã€å®è§‚ç»æµä¸åäººæ¨æ–‡ï¼ˆç‰¹æœ—æ™®/é©¬æ–¯å…‹/CZï¼‰"""
    
    def __init__(self, ai_model: str, api_key: str):
        super().__init__(AgentRole.NEWS_ANALYST, ai_model, api_key)
        self.api_url = "https://api.deepseek.com/v1/chat/completions"
        self.tracked_celebrities = ["Donald Trump", "Elon Musk", "CZ", "èµµé•¿é¹", "@elonmusk", "@cz_binance"]
        self.news_api_url = settings.news_api_url
        self.last_new_id = 0
        self.last_result = {}
    
    async def _fetch_news_from_api(self) -> List[Dict]:
        """ä»é…ç½®çš„æ–°é—»APIè·å–æ–°é—»æ•°æ®"""
        try:
            logger.info(f"ğŸ“° æ­£åœ¨ä»æ–°é—»APIè·å–æ•°æ®: {self.news_api_url}")
            
            async with aiohttp.ClientSession() as session:
                async with session.get(self.news_api_url, timeout=30) as response:
                    if response.status == 200:
                        news_data = await response.json()
                        logger.info(f"âœ… æˆåŠŸè·å– {len(news_data)} æ¡æ–°é—»")
                        return news_data
                    else:
                        logger.warning(f"âš ï¸ æ–°é—»APIå“åº”å¼‚å¸¸: {response.status}")
                        return []
        except aiohttp.ClientTimeout:
            logger.warning("â° æ–°é—»APIè¯·æ±‚è¶…æ—¶")
            return []
        except Exception as e:
            logger.exception(f"âŒ è·å–æ–°é—»æ•°æ®å¤±è´¥: {e}")
            return []
    
    async def analyze(
        self,
        symbol: str,
        market_data: Dict,
        additional_data: Optional[Dict] = None
    ) -> AgentAnalysis:
        """åˆ†ææ–°é—»ã€å®è§‚ç»æµå’ŒæŒ‡å®šåäººæ¨æ–‡å½±å“"""
        try:
            # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„æ–°é—»æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä»APIè·å–
            news_data = additional_data.get('news', []) if additional_data else []
            positions = additional_data.get('positions', [])
            
            tweet_data = additional_data.get('tweets', []) if additional_data else []

            # è¿‡æ»¤ï¼šä»…ä¿ç•™æ¥è‡ªå…³æ³¨äººç‰©çš„æ¨æ–‡
            tweet_data = [
                tweet for tweet in tweet_data
                if any(name.lower() in (tweet.get("author", "") + tweet.get("username", "")).lower()
                       for name in self.tracked_celebrities)
            ]

            role_context = self._build_role_context(symbol, news_data, tweet_data)
            
            # æ„å»ºå®Œæ•´çš„æç¤ºè¯ï¼ˆæ³¨å…¥é£æ§é…ç½®ï¼‰
            prompt = f"""
å½“å‰äº¤æ˜“å¯¹: {symbol}
å¸‚åœºæ•°æ®ï¼š{json.dumps(market_data, ensure_ascii=False, indent=2)}

{role_context}
{self._analyze_position_status(symbol, positions, market_data)}
è¯·åˆ†æå¹¶æä¾›å»ºè®®ï¼Œè¿”å›æ ‡å‡†çš„JSONæ ¼å¼åˆ†æã€‚
æ³¨æ„ï¼šå»ºè®®å¿…é¡»ç¬¦åˆç³»ç»Ÿé£æ§è§„åˆ™ï¼
"""
            logger.info(f"æ–°é—»åˆ†æå¸ˆæç¤ºè¯: {NEWS_ANALYST_PROMPT}\n {prompt}")
            async with aiohttp.ClientSession() as session:
                headers = {
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                }
                
                payload = {
                    "model": "deepseek-chat",
                    "messages": [
                        {"role": "system", "content": NEWS_ANALYST_PROMPT},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.7,
                    "max_tokens": 800
                }
                
                async with session.post(self.api_url, headers=headers, json=payload) as response:
                    data = await response.json()
                    
                    # æ£€æŸ¥APIå“åº”æ ¼å¼
                    if 'choices' not in data:
                        logger.error(f"APIå“åº”æ ¼å¼é”™è¯¯: {data}")
                        raise Exception(f"APIå“åº”ç¼ºå°‘choiceså­—æ®µ: {data}")
                    
                    if not data['choices'] or len(data['choices']) == 0:
                        logger.error(f"APIå“åº”choicesä¸ºç©º: {data}")
                        raise Exception("APIå“åº”choicesä¸ºç©º")
                    
                    content = data['choices'][0]['message']['content']
            
            result = self._parse_response(content)
            return AgentAnalysis(
                agent_role=self.role,
                recommendation=result.get('recommendation', 'hold'),
                confidence=float(result.get('confidence', 0.5)),
                reasoning=result.get('reasoning', 'æ–°é—»åˆ†æ'),
                key_metrics=result.get('key_metrics', {}),
                risk_score=float(result.get('risk_score', 0.5)),
                priority=4
            )
            # return self.last_result
            
        except Exception as e:
            logger.exception(f"æ–°é—»åˆ†æå¤±è´¥: {e}")
            return AgentAnalysis(
                agent_role=self.role,
                recommendation="hold",
                confidence=0.0,
                reasoning=f"åˆ†æå¤±è´¥: {str(e)}",
                key_metrics={},
                risk_score=0.5,
                priority=4
            )

    def _build_role_context(self, symbol: str, news: List[Dict], tweets: List[Dict]) -> str:
        """æ„å»ºåˆ†æä¸Šä¸‹æ–‡ï¼ŒåŒ…æ‹¬æ–°é—»ä¸åäººæ¨æ–‡ä»¥åŠè´Ÿé¢æ–°é—»åˆ†çº§"""
        # å¤„ç†æ–°é—»æ•°æ®ï¼Œæå–å…³é”®ä¿¡æ¯
        processed_news = []
        for item in news:
            if item.get("sentiment_score") == 0.5:
                continue
            news_time = item.get("received_at")
            # è¶…è¿‡ä¸€å°æ—¶ è¿‡æ»¤
            if news_time:
                try:
                    # å°è¯•è§£æISOæ ¼å¼æ—¶é—´ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
                    if isinstance(news_time, str):
                        # å»æ‰å¾®ç§’éƒ¨åˆ†ï¼Œç»Ÿä¸€å¤„ç†
                        if 'T' in news_time:
                            # ISOæ ¼å¼: 2025-11-03T12:31:23.153883
                            news_time = news_time.split('.')[0]  # å»æ‰å¾®ç§’
                            news_datetime = datetime.datetime.strptime(news_time, "%Y-%m-%dT%H:%M:%S")
                        else:
                            # æ ‡å‡†æ ¼å¼: 2025-11-03 12:31:23
                            news_datetime = datetime.datetime.strptime(news_time, "%Y-%m-%d %H:%M:%S")
                        
                        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡1å°æ—¶
                        if datetime.datetime.now() - news_datetime > datetime.timedelta(hours=3):
                            continue
                except Exception as e:
                    logger.warning(f"è§£ææ–°é—»æ—¶é—´å¤±è´¥: {news_time}, é”™è¯¯: {e}")
                    # æ—¶é—´è§£æå¤±è´¥ï¼Œä¿ç•™è¯¥æ–°é—»
                    pass
            
            processed_item = {
                "id": item.get("id", ""),
                "summary": item.get("summary", ""),
                "sentiment": item.get("sentiment", "neutral"),
                "sentiment_score": item.get("sentiment_score", 0.5),
                "mentioned_coins": item.get("mentioned_coins", []),
                "is_major": item.get("is_major", False),
                "received_at": item.get("received_at", ""),
                "source_url": item.get("source_url", "")
            }
            # å¦‚æœæ˜¯é‡å¤§æ–°é—»ï¼ŒåŒ…å«åŸæ–‡å†…å®¹
            if item.get("is_major") and item.get("original_content"):
                processed_item["original_content"] = item.get("original_content")
            processed_news.append(processed_item.get("summary"))
        
        news_json = json.dumps(processed_news, ensure_ascii=False, indent=2) if processed_news else "æ— "
        tweet_json = json.dumps(tweets, ensure_ascii=False, indent=2) if tweets else "æ— "

        return f"""
ä½œä¸ºæ–°é—»åˆ†æå¸ˆï¼Œè¯·é‡ç‚¹å…³æ³¨ä»¥ä¸‹ä¸‰ç±»ä¿¡æ¯ï¼š

1. åŠ å¯†è´§å¸ç›¸å…³æ–°é—»ï¼š
   - é¡¹ç›®é‡å¤§å…¬å‘Šã€åˆä½œä¼™ä¼´å…³ç³»
   - æŠ€æœ¯å‡çº§ã€ä»£å¸ç»æµå˜åŠ¨
   - ç›‘ç®¡æ”¿ç­–ã€çªå‘æ–°é—»äº‹ä»¶
   - é‡ç‚¹å…³æ³¨æ–°é—»ä¸­æåŠçš„å¸ç§ï¼š{symbol}

2. å®è§‚ç»æµç¯å¢ƒï¼š
   - ç¾è”å‚¨åˆ©ç‡ã€é€šèƒ€æ•°æ®
   - åœ°ç¼˜æ”¿æ²»é£é™©ã€å…¨çƒé‡‘èå¸‚åœºåŠ¨æ€

3. åäººæ¨æ–‡å½±å“ï¼š
   è¯·ç‰¹åˆ«å…³æ³¨ä»¥ä¸‹äººç‰©æ˜¯å¦å¯¹åŠ å¯†è´§å¸å‘è¡¨äº†è§‚ç‚¹ï¼š
   - Elon Muskï¼ˆé©¬æ–¯å…‹ï¼‰
   - Donald Trumpï¼ˆç‰¹æœ—æ™®ï¼‰
   - CZï¼ˆèµµé•¿é¹ï¼‰

ä»–ä»¬çš„å‘è¨€å¯èƒ½å½±å“å¸‚åœºæƒ…ç»ªä¸æ–¹å‘ã€‚

æ–°é—»åˆ†æé‡ç‚¹ï¼š
- æƒ…ç»ªè¯„åˆ†ï¼špositive(>0.6) åˆ©å¥½ï¼Œnegative(<0.4) åˆ©ç©ºï¼Œneutral(0.4-0.6) ä¸­æ€§
- é‡å¤§æ–°é—»ï¼šéœ€è¦é‡ç‚¹å…³æ³¨
- æåŠå¸ç§ï¼šmentioned_coins ä¸­åŒ…å«ç›¸å…³å¸ç§çš„æ–°é—»æ›´ç›¸å…³
- æ—¶é—´å› ç´ ï¼šæœ€è¿‘ä¸€ä¸ªå°æ—¶å†…çš„æ–°é—»æ¯”æ—§æ–°é—»å½±å“æ›´å¤§

å¼ºçƒˆåšç©ºä¿¡å·ï¼ˆè´Ÿé¢æ–°é—»ï¼‰ï¼š
1. ç›‘ç®¡æ‰“å‡»æ–°é—»ï¼ˆSECè¯‰è®¼ã€ç¦ä»¤ç­‰ï¼‰
2. é¡¹ç›®å®‰å…¨æ¼æ´æˆ–é»‘å®¢æ”»å‡»
3. å›¢é˜Ÿå†…éƒ¨åˆ†è£‚æˆ–åˆ›å§‹äººç¦»èŒ
4. æŠ€æœ¯é‡å¤§ç¼ºé™·è¢«æ›å…‰
5. ç«äº‰å¯¹æ‰‹æ¨å‡ºé¢ è¦†æ€§äº§å“
6. å®è§‚ç»æµæ¶åŒ–ï¼ˆåŠ æ¯ã€æµåŠ¨æ€§æ”¶ç´§ï¼‰

åäººæ¨æ–‡åšç©ºå½±å“ï¼š
- Elon Musk: å¯¹åŠ å¯†è´§å¸çš„è´Ÿé¢è¯„è®º
- Donald Trump: å¯¹åŠ å¯†è´§å¸çš„ç›‘ç®¡ç«‹åœº
- CZ: äº¤æ˜“æ‰€ä¸‹æ¶ä»£å¸ã€ç›‘ç®¡åˆè§„é—®é¢˜

è´Ÿé¢æ–°é—»ä¸¥é‡ç¨‹åº¦åˆ†çº§ï¼š
- ä¸¥é‡ï¼šç›´æ¥å½±å“é¡¹ç›®ç”Ÿå­˜ï¼ˆå¦‚ç›‘ç®¡ç¦ä»¤ã€é‡å¤§å®‰å…¨äº‹æ•…ï¼‰
- ä¸­ç­‰ï¼šå½±å“çŸ­æœŸä»·æ ¼ä½†å¯æ¢å¤ï¼ˆå¦‚å›¢é˜Ÿæˆå‘˜ç¦»èŒã€æŠ€æœ¯bugï¼‰
- è½»å¾®ï¼šæš‚æ—¶æ€§è´Ÿé¢æƒ…ç»ªï¼ˆå¦‚å¸‚åœºæµè¨€ã€å°è§„æ¨¡æ‰¹è¯„ï¼‰

ä»¥ä¸‹æ˜¯æœ€è¿‘æ–°é—»å†…å®¹ï¼ˆè¿‡å»3å°æ—¶ï¼‰å’Œè¿‘æœŸæ¨æ–‡ï¼š
{news_json}



è¯·ç»¼åˆåˆ†ææ­£é¢å’Œè´Ÿé¢å› ç´ å¯¹ {symbol} çš„æ½œåœ¨å½±å“ï¼Œç»™å‡ºå¹³è¡¡çš„äº¤æ˜“å»ºè®®ï¼ˆåŒ…æ‹¬åšç©ºæœºä¼šï¼‰ã€‚
ç‰¹åˆ«å…³æ³¨æ–°é—»çš„æƒ…ç»ªè¯„åˆ†å’Œæ˜¯å¦æåŠç›¸å…³å¸ç§ã€‚
"""
    def _analyze_position_status(self, symbol: str, positions: Optional[List[Dict]], market_data: Dict) -> str:
        """åˆ†ææŒä»“çŠ¶æ€"""
        # ä»æŒä»“åˆ—è¡¨ä¸­æ‰¾åˆ°å¯¹åº”symbolçš„æŒä»“
        position = None
        if positions:
            for pos in positions:
                if pos.get('symbol') == symbol:
                    position = pos
                    break
        
        if not position:
            return f"""
å½“å‰{symbol}æŒä»“çŠ¶æ€ï¼š
- æ— æŒä»“
- å¯æ‰§è¡Œæ“ä½œï¼šbuy(åšå¤š), short(åšç©º), hold(è§‚æœ›)
"""
        
        position_type = position.get('position_type', 'buy')  # 'buy'è¡¨ç¤ºå¤šä»“, 'short'è¡¨ç¤ºç©ºä»“
        amount = position.get('amount', 0)
        # ä¼˜å…ˆä½¿ç”¨entry_priceï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨average_price
        entry_price = position.get('entry_price') if position.get('entry_price') else position.get('average_price', 0)
        current_price = market_data.get('price', 0)
        
        if position_type == 'buy' or position_type == 'long':
            # å¤šä»“
            unrealized_pnl = (current_price - entry_price) * amount if entry_price > 0 else 0
            unrealized_pnl_pct = ((current_price - entry_price) / entry_price * 100) if entry_price > 0 else 0
            return f"""
å½“å‰{symbol}æŒä»“çŠ¶æ€ï¼š
- æŒä»“ç±»å‹ï¼šå¤šä»“ï¼ˆåšå¤šï¼‰
- æŒä»“æ•°é‡ï¼š{amount:.6f}
- å…¥åœºä»·æ ¼ï¼š${entry_price:.4f}
- å½“å‰ä»·æ ¼ï¼š${current_price:.4f}
- æœªå®ç°ç›ˆäºï¼š${unrealized_pnl:.2f} ({unrealized_pnl_pct:+.2f}%)
- å¯æ‰§è¡Œæ“ä½œï¼šsell(å¹³å¤šä»“), hold(ç»§ç»­æŒæœ‰)
- **å¦‚æœå›¢é˜Ÿåˆ†æçœ‹è·Œï¼Œåº”è€ƒè™‘sellå¹³ä»“æ­¢æŸæˆ–æ­¢ç›ˆ**
"""
        else:
            # ç©ºä»“
            unrealized_pnl = (entry_price - current_price) * amount if entry_price > 0 else 0
            unrealized_pnl_pct = ((entry_price - current_price) / entry_price * 100) if entry_price > 0 else 0
            return f"""
å½“å‰{symbol}æŒä»“çŠ¶æ€ï¼š
- æŒä»“ç±»å‹ï¼šç©ºä»“ï¼ˆåšç©ºï¼‰
- æŒä»“æ•°é‡ï¼š{amount:.6f}
- å…¥åœºä»·æ ¼ï¼š${entry_price:.4f}
- å½“å‰ä»·æ ¼ï¼š${current_price:.4f}
- æœªå®ç°ç›ˆäºï¼š${unrealized_pnl:.2f} ({unrealized_pnl_pct:+.2f}%)
- å¯æ‰§è¡Œæ“ä½œï¼šcover(å¹³ç©ºä»“), hold(ç»§ç»­æŒæœ‰)
- **å¦‚æœå›¢é˜Ÿåˆ†æçœ‹æ¶¨ï¼Œåº”è€ƒè™‘coverå¹³ä»“æ­¢æŸæˆ–æ­¢ç›ˆ**
"""
    def _parse_response(self, content: str) -> Dict:
        """è§£æAIå“åº”"""
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            return {}

